{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download images from three different sources: Bing, DuckDuckGo, Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import DuckDuckGoImages as ddg\n",
    "from google_images_download import google_images_download\n",
    "from difPy import dif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetBaseFolder = \"../tmp\"\n",
    "classes = [\"cat\", \"dog\"]\n",
    "datasets = [\"bing\", \"ddg\", \"google\"]\n",
    "\n",
    "bingFolder = os.path.join(datasetBaseFolder, \"bing\")\n",
    "ddgFolder = os.path.join(datasetBaseFolder, \"ddg\")\n",
    "googleFolder = os.path.join(datasetBaseFolder, \"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    [\"cat\", \"little cat\", \"small cat\", \"calico cat\", \"cute cat\", \"norwegian forest cat\", \"black cat\",\n",
    "        \"orange cat\", \"grey cat\", \"white cat\", \"fluffy cat\", \"siamese cat\", \"tabby cat\",\n",
    "        \"munchkin cat\", \"persian cat\", \"angora cat\", \"bengal cat\", \"chartreux cat\", \"savannah cat\", \"ragdoll cat\"],\n",
    "\n",
    "    [\"dog\", \"little dog\", \"small dog\", \"brown dog\", \"cute dog\",\n",
    "     \"big dog\", \"black dog\", \"boxer dog\", \"grey dog\", \"white dog\",\n",
    "     \"german shepherd dog\", \"golden retriever dog\", \"labrador dog\", \"samoyed dog\", \"siberian husky dog\",\n",
    "     \"chihuahua dog\", \"bulldog\", \"doberman dog\", \"pug dog\", \"rottweiler dog\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temporary folders where download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataFolder = os.path.join(datasetBaseFolder, dataset)\n",
    "\n",
    "    for cls in classes:\n",
    "        clsFolder = os.path.join(dataFolder, cls)\n",
    "\n",
    "        if not os.path.exists(clsFolder):\n",
    "            print(\"[üìÇ CREATED FOLDER] {}\".format(clsFolder))\n",
    "            os.makedirs(clsFolder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[üíæ BING DOWNLOADER]\")\n",
    "\n",
    "for query, folder in zip(queries, classes):\n",
    "    print(\"\\n[üóÉÔ∏è INFO] Downloading images for class {}\".format(folder))\n",
    "\n",
    "    classDir = os.path.join(bingFolder, folder)\n",
    "\n",
    "    for q in query:\n",
    "        print(\"[üîç INFO] Downloading images for query {}\".format(q))\n",
    "        \n",
    "        downloadDir = os.path.join(classDir, q)\n",
    "        os.system(\n",
    "            \"python3 bbid.py -s \\\"{}\\\" -o \\\"{}\\\" --limit 400\".format(query, downloadDir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DuckDuckGo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[üíæ DDG DOWNLOADER]\")\n",
    "\n",
    "for query, folder in zip(queries, classes):    \n",
    "    print(\"\\n[üóÉÔ∏è INFO] Downloading images for class {}\".format(folder))\n",
    "\n",
    "    classDir = os.path.join(ddgFolder, folder)\n",
    "\n",
    "    for q in query:\n",
    "        print(\"[üîç INFO] Downloading images for query {}\".format(q))\n",
    "        \n",
    "        downloadDir = os.path.join(classDir, q)\n",
    "        if not os.path.exists(downloadDir):\n",
    "            os.makedirs(downloadDir)\n",
    "\n",
    "        ddg.download(q, folder=downloadDir, parallel=True, max_urls=2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer** In order to use this tool for download images from Google, it is necessary to download the [chromedriver](https://chromedriver.chromium.org/downloads) and put it in the same folder specified below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = google_images_download.googleimagesdownload()\n",
    "chromedriver_dir = \"C:\\chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[üíæ GOOGLE DOWNLOADER]\")\n",
    "\n",
    "for query, folder in zip(queries, classes):\n",
    "    print(\"\\n[üóÉÔ∏è INFO] Downloading images for class {}\".format(folder))\n",
    "\n",
    "    classDir = os.path.join(googleFolder, folder)\n",
    "\n",
    "    arguments = {\n",
    "        \"keywords\": \",\".join(query),\n",
    "        \"limit\": 400,\n",
    "        \"chromedriver\": chromedriver_dir,\n",
    "        \"output_directory\": classDir\n",
    "    }\n",
    "\n",
    "    paths = response.download(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate removal for queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[üóëÔ∏è DUPLICATE REMOVAL]\")\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(\"\\n[üóÉÔ∏è DATASET] {}\".format(dataset))\n",
    "    datasetFolder = os.path.join(datasetBaseFolder, dataset)\n",
    "\n",
    "    for query, folder in zip(queries, classes):\n",
    "        classDir = os.path.join(datasetFolder, folder)\n",
    "        print(\"[üîç INFO] Removing duplicates in the dataset {}\".format(classDir))\n",
    "\n",
    "        for q in query:\n",
    "            print(\"[üîç INFO] Removing duplicates for the query {}\".format(q))\n",
    "\n",
    "            queryDir = os.path.join(classDir, q)\n",
    "            search = dif(queryDir, similarity=\"normal\")\n",
    "\n",
    "            for imgKey in search.result:\n",
    "                print(\"[‚úîÔ∏è INFO] Found duplicates for the image {}\".format(imgKey))\n",
    "                \n",
    "                duplicates = search.result[imgKey][\"duplicates\"]\n",
    "\n",
    "                for duplicate in duplicates:\n",
    "                    print(\"[üóëÔ∏è INFO] Deleted duplicate {}\".format(imgKey))\n",
    "                    if os.path.exists(duplicate):\n",
    "                        os.remove(duplicate)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
