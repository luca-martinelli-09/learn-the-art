{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial samples generator\n",
    "Generate the adversarial samples to test the models\n",
    "\n",
    "**Authors**\n",
    "\n",
    "`Marco Alecci <https://github.com/MarcoAlecci>`\n",
    "\n",
    "`Francesco Marchiori <https://github.com/FrancescoMarchiori>`\n",
    "\n",
    "`Luca Martinelli <https://github.com/luca-martinelli-09>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/luca-martinelli-09/learn-the-art/blob/main/FGSM_tuning/tuning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# @markdown ## Setup project\n",
    "# @markdown This section will download the datasets from GitHub to use for the training phase\n",
    "\n",
    "if not os.path.exists(\"./datasets\"):\n",
    "    !git clone \"https://github.com/luca-martinelli-09/learn-the-art.git\"\n",
    "\n",
    "    %cd learn-the-art/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "datasetToFolder = {\"ddg\": \"ddg\", \"bing\": \"bing\", \"google\": \"google\"}\n",
    "googleModelsDir = None\n",
    "\n",
    "if IN_COLAB:\n",
    "  !pip install torchattacks\n",
    "\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "\n",
    "  googleModelsDir = \"/content/drive/MyDrive/UniversitaÌ€/Magistrale/II Anno/I Semestre/Advanced Topics in Computer and Network Security/Project/Models\"\n",
    "  \n",
    "  datasetToFolder = {\"ddg\": \"DuckDuckGo\", \"bing\": \"Bing\", \"google\": \"Google\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "from torchattacks import FGSM\n",
    "\n",
    "from imageLimitedDataset import ImageLimitedDataset\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Shuffle the dataset\n",
    "shuffleDataset = False  # @param {type: \"boolean\"}\n",
    "\n",
    "# @markdown Reduce the size of the dataset\n",
    "datasetSize = 100  # @param {type: \"integer\"}\n",
    "\n",
    "# @markdown Decide whether to adapt the attack or not. When True, adversarial samples are tested after the generation in order to see if the accuracy of the same model on which it has been trained goes below a threshold, otherwise reiterate the whole process with a different eps value\n",
    "adapt = False  # @param {type: \"boolean\"}\n",
    "\n",
    "# @markdown Threshold for the maximum value of the accuracy\n",
    "accThreshold = 0.3 # @param {type: \"number\"}\n",
    "\n",
    "# @markdown How much to increase the value of eps when using adapting attack\n",
    "epsStep = 0.05 # @param {type: \"number\"}\n",
    "\n",
    "# @markdown Set the value of epsilon\n",
    "epsilon = 0.05  # @param {type: \"number\"}\n",
    "\n",
    "# @markdown Set the maximum value of epsilon\n",
    "maxEpsilon = 0.2  # @param {type: \"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetsGenerateOnly = [\"google\"] # Use this if you want to select only one dataset from bing, ddg or google\n",
    "datasetsGenerateOnly = [\"bing\", \"google\", \"ddg\"] # Use this if you want to get all the datasets\n",
    "\n",
    "# modelsGenerateOnly = [\"vgg\"] # Use this if you want to select only one model from alexnet, resnet or vgg, None if select all\n",
    "modelsGenerateOnly = [\"alexnet\", \"resnet\", \"vgg\"] # Use this if you want to select all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarialDir = \"./adversarial_samples\"\n",
    "datasetsDir = \"../datasets\"\n",
    "modelsDir = googleModelsDir if googleModelsDir else \"../models\"\n",
    "\n",
    "inputSize = 224 # Specified for alexnet, resnet, vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 151836\n",
    "\n",
    "\n",
    "def setSeed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "setSeed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubDirs(dir):\n",
    "    return [x for x in os.listdir(dir) if os.path.isdir(os.path.join(dir, x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassPercents(sizes):\n",
    "    totalSize = np.sum(np.array(sizes))\n",
    "    percents = []\n",
    "    for size in sizes:\n",
    "        percents.append(int(round((size / totalSize) * 100)))\n",
    "\n",
    "    return percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMathAdversarials(dataloader, classes, fileNames, attack, saveDir, shuffled=False):\n",
    "\n",
    "    i = 0;\n",
    "    for images, labels in dataloader:\n",
    "        adversarials = attack(images, labels)\n",
    "\n",
    "        for adversarial, label in zip(adversarials, labels):\n",
    "            image = transforms.ToPILImage()(adversarial).convert(\"RGB\")\n",
    "            path = os.path.join(saveDir, classes[label])\n",
    "\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "\n",
    "            imageName = i + \".jpg\" if shuffled else os.path.basename(fileNames[i][0])\n",
    "            image.save(os.path.join(path, imageName), \"JPEG\")\n",
    "\n",
    "            i += 1\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                print(\"Sample #\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printGPUStats():\n",
    "    print('Using device:', device)\n",
    "    print()\n",
    "\n",
    "    # Additional Info when using cuda\n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print('[ðŸ’» MEMORY USAGE]')\n",
    "        print('[ðŸ“Œ ALLOCATED]', round(\n",
    "            torch.cuda.memory_allocated(0) / 1024 ** 3, 1), 'GB')\n",
    "        print('[ðŸ§® CACHED]', round(\n",
    "            torch.cuda.memory_reserved(0) / 1024 ** 3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestScores(hist, key, min=False):\n",
    "    scores = [x[key] for x in hist]\n",
    "\n",
    "    if min:\n",
    "        i = np.argmin(np.array(scores))\n",
    "    else:\n",
    "        i = np.argmax(np.array(scores))\n",
    "\n",
    "    return hist[i], i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanAndSDT(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(labels, predicted):\n",
    "    acc = torch.sum(predicted == labels) / len(predicted)\n",
    "\n",
    "    tp = (labels * predicted).sum()\n",
    "    tn = ((1 - labels) * (1 - predicted)).sum()\n",
    "    fp = ((1 - labels) * predicted).sum()\n",
    "    fn = (labels * (1 - predicted)).sum()\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return acc, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(model, dataloader):\n",
    "    model.eval()\n",
    "    labelsOutputs = torch.tensor([]).to(device, non_blocking=True)\n",
    "    labelsTargets = torch.tensor([]).to(device, non_blocking=True)\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        labelsOutputs = torch.cat([labelsOutputs, preds], dim=0)\n",
    "        labelsTargets = torch.cat([labelsTargets, labels], dim=0)\n",
    "\n",
    "    acc, precision, recall, f1 = getScores(labelsTargets, labelsOutputs)\n",
    "\n",
    "    return {\n",
    "        \"acc\": acc.cpu().numpy(),\n",
    "        \"precision\": precision.cpu().numpy(),\n",
    "        \"recall\": recall.cpu().numpy(),\n",
    "        \"f1\": f1.cpu().numpy()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModelsOnDataset(datasetFolder, datasetInfo):\n",
    "    global modelsDir, inputSize\n",
    "\n",
    "    modelsEvals = []\n",
    "\n",
    "    # Get the images and calculate mean and standard deviation\n",
    "    imageDataset = torchvision.datasets.ImageFolder(\n",
    "        datasetFolder, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "        \n",
    "    for cls in imageDataset.classes:\n",
    "        cls_index = imageDataset.class_to_idx[cls]\n",
    "        num_cls = np.count_nonzero(\n",
    "            np.array(imageDataset.targets) == cls_index)\n",
    "        \n",
    "        print(\"\\t[ðŸ§® # ELEMENTS] {}: {}\".format(cls, num_cls))\n",
    "    \n",
    "    imageDataloader = DataLoader(imageDataset, batch_size=128)\n",
    "    \n",
    "    mean, std = getMeanAndSDT(imageDataloader)\n",
    "\n",
    "    # Setup for normalization\n",
    "    dataTransform = transforms.Compose([\n",
    "        transforms.Resize(inputSize),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    testDataset = ImageLimitedDataset(\n",
    "        datasetFolder, transform=dataTransform, use_cache=True, check_images=False)\n",
    "\n",
    "    setSeed(SEED)\n",
    "    testDataLoader = DataLoader(\n",
    "        testDataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    # Evaluate every model\n",
    "    for root, _, fnames in sorted(os.walk(modelsDir, followlinks=True)):\n",
    "        for fname in sorted(fnames):\n",
    "            path = os.path.join(root, fname)\n",
    "\n",
    "            try:\n",
    "                modelData = torch.load(path)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            modelDataset = modelData[\"dataset\"]\n",
    "            modelName = modelData[\"model_name\"]\n",
    "            modelPercents = \"/\".join([str(x)\n",
    "                                     for x in getClassPercents(modelData[\"dataset_sizes\"])])\n",
    "\n",
    "            print()\n",
    "            print(\"[ðŸ§® EVALUATING] {} - {} {}\".format(\n",
    "                modelDataset,\n",
    "                modelName,\n",
    "                modelPercents\n",
    "            ))\n",
    "\n",
    "            modelToTest = modelData[\"model\"]\n",
    "            modelToTest = modelToTest.to(device, non_blocking=True)\n",
    "\n",
    "            scores = evaluateModel(modelToTest, testDataLoader)\n",
    "\n",
    "            modelsEvals.append({\n",
    "                    \"dataset\": datasetInfo[\"dataset\"],\n",
    "                    \"isMath\": datasetInfo[\"math\"],\n",
    "                    \"attack\": datasetInfo[\"attack\"],\n",
    "                    \"advModel\": datasetInfo[\"model\"],\n",
    "                    \"advBalancing\": datasetInfo[\"balancing\"],\n",
    "\n",
    "                    \"model\": modelName,\n",
    "                    \"modelDataset\": modelDataset,\n",
    "                    \"balancing\": modelPercents,\n",
    "                    \"acc\": scores[\"acc\"],\n",
    "                    \"precision\": scores[\"precision\"],\n",
    "                    \"recall\": scores[\"recall\"],\n",
    "                    \"f1\": scores[\"f1\"],\n",
    "                })\n",
    "            \n",
    "            print(\"\\tAcc: {:.4f}\".format(scores[\"acc\"]))\n",
    "            print(\"\\tPre: {:.4f}\".format(scores[\"precision\"]))\n",
    "            print(\"\\tRec: {:.4f}\".format(scores[\"recall\"]))\n",
    "            print(\"\\tF-Score: {:.4f}\".format(scores[\"f1\"]))\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    return modelsEvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesEvaluations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetsToGenerate = getSubDirs(datasetsDir) if not datasetsGenerateOnly else datasetsGenerateOnly\n",
    "\n",
    "if not adapt:\n",
    "    for dataset in datasetsToGenerate:\n",
    "        print(\"\\n\" + \"-\" * 15)\n",
    "        print(\"[ðŸ—ƒï¸ SOURCE DATASET] {}\".format(dataset))\n",
    "\n",
    "        datasetDir = os.path.join(datasetsDir, dataset)\n",
    "        testDir = os.path.join(datasetDir, \"test\")\n",
    "\n",
    "        datasetAdvDir = os.path.join(adversarialDir, dataset)\n",
    "        mathAttacksDir = os.path.join(datasetAdvDir, \"math\")\n",
    "\n",
    "        if not os.path.exists(mathAttacksDir):\n",
    "            os.makedirs(mathAttacksDir)\n",
    "\n",
    "        toTensor = transforms.Compose([transforms.ToTensor()])\n",
    "        testDataset = ImageLimitedDataset(\n",
    "            testDir, transform=toTensor, slices=[slice(0, datasetSize)], use_cache=False, check_images=False)\n",
    "\n",
    "        setSeed(SEED)\n",
    "        testDataLoader = DataLoader(\n",
    "            testDataset, batch_size=16, num_workers=0, shuffle=shuffleDataset)\n",
    "        \n",
    "        for root, _, fnames in sorted(os.walk(os.path.join(modelsDir, datasetToFolder[dataset]), followlinks=True)):\n",
    "            for fname in sorted(fnames):\n",
    "                path = os.path.join(root, fname)\n",
    "\n",
    "                try:\n",
    "                    modelData = torch.load(path)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                modelDataset = modelData[\"dataset\"]\n",
    "                modelName = modelData[\"model_name\"]\n",
    "\n",
    "                if not modelName in modelsGenerateOnly:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                \n",
    "                modelPercents = \"_\".join([str(x)\n",
    "                                        for x in getClassPercents(modelData[\"dataset_sizes\"])])\n",
    "                model = modelData[\"model\"].to(device)\n",
    "\n",
    "                attacks = {\n",
    "                    \"FGSM\": FGSM(model, eps=epsilon),\n",
    "                }\n",
    "\n",
    "                for attack in attacks:\n",
    "                    attacker = attacks[attack]\n",
    "\n",
    "                    attackDir = os.path.join(\n",
    "                        mathAttacksDir, attack)\n",
    "                    saveDir = os.path.join(\n",
    "                        attackDir, modelName + \"/\" + modelPercents)\n",
    "                    \n",
    "                    if not os.path.exists(saveDir):\n",
    "                        os.makedirs(saveDir)\n",
    "\n",
    "                    currentTime = time.time()\n",
    "                    print(\"[âš”ï¸ ADVERSARIAL] {} - {} - {} {}\".format(\n",
    "                        attack,\n",
    "                        modelDataset,\n",
    "                        modelName,\n",
    "                        modelPercents\n",
    "                    ))\n",
    "\n",
    "                    setSeed(SEED)\n",
    "                    saveMathAdversarials(testDataLoader, testDataset.classes,\n",
    "                                        testDataset.imgs, attacker, saveDir, shuffled=shuffleDataset)\n",
    "\n",
    "                    elapsedTime = time.time() - currentTime\n",
    "                    print(\"Elapsed seconds:\", elapsedTime)\n",
    "                    timesEvaluations.append({\n",
    "                        \"dataset\": dataset,\n",
    "                        \"math\": True,\n",
    "                        \"attack\": attack,\n",
    "                        \"model\": modelName,\n",
    "                        \"modelDataset\": modelDataset,\n",
    "                        \"balancing\": modelPercents.replace(\"_\", \"/\"),\n",
    "                        \"time\": elapsedTime,\n",
    "                    })\n",
    "\n",
    "                    torch.cuda.empty_cache()\n",
    "else: # When using adapting attack\n",
    "    for dataset in datasetsToGenerate:\n",
    "        print(\"\\n\" + \"-\" * 15)\n",
    "        print(\"[ðŸ—ƒï¸ SOURCE DATASET] {}\".format(dataset))\n",
    "\n",
    "        datasetDir = os.path.join(datasetsDir, dataset)\n",
    "        testDir = os.path.join(datasetDir, \"test\")\n",
    "\n",
    "        datasetAdvDir = os.path.join(adversarialDir, dataset)\n",
    "        mathAttacksDir = os.path.join(datasetAdvDir, \"math\")\n",
    "\n",
    "        if not os.path.exists(mathAttacksDir):\n",
    "            os.makedirs(mathAttacksDir)\n",
    "\n",
    "        toTensor = transforms.Compose([transforms.ToTensor()])\n",
    "        testDataset = ImageLimitedDataset(\n",
    "            testDir, transform=toTensor, slices=[slice(0, datasetSize)], use_cache=False, check_images=False)\n",
    "\n",
    "        setSeed(SEED)\n",
    "        testDataLoader = DataLoader(\n",
    "            testDataset, batch_size=16, num_workers=0, shuffle=shuffleDataset)\n",
    "        \n",
    "        for root, _, fnames in sorted(os.walk(os.path.join(modelsDir, datasetToFolder[dataset]), followlinks=True)):\n",
    "            for fname in sorted(fnames):\n",
    "                path = os.path.join(root, fname)\n",
    "\n",
    "                try:\n",
    "                    modelData = torch.load(path)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                modelDataset = modelData[\"dataset\"]\n",
    "                modelName = modelData[\"model_name\"]\n",
    "\n",
    "                if not modelName in modelsGenerateOnly:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                \n",
    "                modelPercents = \"_\".join([str(x)\n",
    "                                        for x in getClassPercents(modelData[\"dataset_sizes\"])])\n",
    "                model = modelData[\"model\"].to(device)\n",
    "\n",
    "                #------------------------------\n",
    "                eps_it = epsilon\n",
    "\n",
    "                while(scores[\"acc\"] > accThreshold and eps_it <= maxEpsilon):\n",
    "                    attacks = {\n",
    "                        \"FGSM\": FGSM(model, eps=eps_it),\n",
    "                    }\n",
    "\n",
    "                    for attack in attacks:\n",
    "                        attacker = attacks[attack]\n",
    "\n",
    "                        attackDir = os.path.join(\n",
    "                            mathAttacksDir, attack)\n",
    "                        saveDir = os.path.join(\n",
    "                            attackDir, modelName + \"/\" + modelPercents)\n",
    "                        \n",
    "                        if not os.path.exists(saveDir):\n",
    "                            os.makedirs(saveDir)\n",
    "\n",
    "                        currentTime = time.time()\n",
    "                        print(\"[âš”ï¸ ADVERSARIAL] {} - {} - {} {}\".format(\n",
    "                            attack,\n",
    "                            modelDataset,\n",
    "                            modelName,\n",
    "                            modelPercents\n",
    "                        ))\n",
    "                        print(\"[ðŸ´â€â˜ ï¸ EPSILON VALUE] {}\".format(eps_it))\n",
    "\n",
    "                        setSeed(SEED)\n",
    "                        saveMathAdversarials(testDataLoader, testDataset.classes,\n",
    "                                            testDataset.imgs, attacker, saveDir, shuffled=shuffleDataset)\n",
    "\n",
    "                        elapsedTime = time.time() - currentTime\n",
    "                        print(\"Elapsed seconds:\", elapsedTime)\n",
    "                        timesEvaluations.append({\n",
    "                            \"dataset\": dataset,\n",
    "                            \"math\": True,\n",
    "                            \"attack\": attack,\n",
    "                            \"model\": modelName,\n",
    "                            \"modelDataset\": modelDataset,\n",
    "                            \"balancing\": modelPercents.replace(\"_\", \"/\"),\n",
    "                            \"time\": elapsedTime,\n",
    "                        })\n",
    "\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                        advDatasetInfo = {\n",
    "                            \"dataset\": dataset,\n",
    "                            \"math\": True,\n",
    "                            \"attack\": attack,\n",
    "                            \"balancing\": modelPercents.replace(\"_\", \"/\"),\n",
    "                            \"model\": modelName,\n",
    "                        }\n",
    "\n",
    "                        print(\"[ðŸ§® EVALUATING] {} - {} {}\".format(\n",
    "                            modelDataset,\n",
    "                            modelName,\n",
    "                            modelPercents\n",
    "                        ))\n",
    "\n",
    "                        modelToTest = modelData[\"model\"]\n",
    "                        modelToTest = modelToTest.to(device, non_blocking=True)\n",
    "\n",
    "                        imageDataset = torchvision.datasets.ImageFolder(\n",
    "                            saveDir, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "                            \n",
    "                        for cls in imageDataset.classes:\n",
    "                            cls_index = imageDataset.class_to_idx[cls]\n",
    "                            num_cls = np.count_nonzero(\n",
    "                                np.array(imageDataset.targets) == cls_index)\n",
    "                        \n",
    "                        imageDataloader = DataLoader(imageDataset, batch_size=128)\n",
    "                        \n",
    "                        mean, std = getMeanAndSDT(imageDataloader)\n",
    "\n",
    "                        # Setup for normalization\n",
    "                        dataTransform = transforms.Compose([\n",
    "                            transforms.Resize(inputSize),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean, std)\n",
    "                        ])\n",
    "\n",
    "                        advDataset = ImageLimitedDataset(\n",
    "                            saveDir, transform=dataTransform, use_cache=True, check_images=False)\n",
    "\n",
    "                        setSeed(SEED)\n",
    "                        advDataLoader = DataLoader(\n",
    "                            advDataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "                        scores = evaluateModel(modelToTest, advDataLoader)\n",
    "                        print(\"[ðŸ“ ACCURACY]\", scores[\"acc\"])\n",
    "                        print()\n",
    "                        eps_it = eps_it + epsStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsEvals = []\n",
    "\n",
    "print(\"[ðŸ§  MODELS EVALUATION - FGSM w/ EPS = {}]\".format(epsilon))\n",
    "\n",
    "# Evaluate models on math attacks folders\n",
    "for dataset in getSubDirs(adversarialDir):\n",
    "    datasetDir = os.path.join(adversarialDir, dataset)\n",
    "    mathAdvDir = os.path.join(datasetDir, \"math\")\n",
    "\n",
    "    if not os.path.exists(mathAdvDir):\n",
    "        continue\n",
    "\n",
    "    for attack in getSubDirs(mathAdvDir):\n",
    "        attackDir = os.path.join(mathAdvDir, attack)\n",
    "\n",
    "        for advModel in getSubDirs(attackDir):\n",
    "            advModelDir = os.path.join(attackDir, advModel)\n",
    "\n",
    "            for advBalancing in getSubDirs(advModelDir):\n",
    "                advDatasetDir = os.path.join(advModelDir, advBalancing)\n",
    "\n",
    "                print(\"\\n\" + \"-\" * 15)\n",
    "                print(\"[ðŸ—ƒï¸ ADVERSARIAL DATASET] {}/{}/{}/{}\".format(dataset, attack, advModel, advBalancing))\n",
    "\n",
    "                advDatasetInfo = {\n",
    "                    \"dataset\": dataset,\n",
    "                    \"math\": True,\n",
    "                    \"attack\": attack,\n",
    "                    \"balancing\": advBalancing.replace(\"_\", \"/\"),\n",
    "                    \"model\": advModel,\n",
    "                }\n",
    "\n",
    "                evals = evaluateModelsOnDataset(advDatasetDir, advDatasetInfo)\n",
    "                modelsEvals.extend(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "modelsEvalsDF = pd.DataFrame(modelsEvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsEvalsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsEvalsDF.to_csv(\"FGSM_Evaluations.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0a60334b6dea779d5814b8ff25532a7426d95956c8adf8de045747e9463d1f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
